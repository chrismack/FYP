from keras.layers import LSTM

confs = [
    {
        'confId': 'epoch',
        'config': [
            
            {
                'trainSize': 0.7,
                'lookback': 8,
                'modelLayers': [
                    LSTM(10),
                ],
                'loss': 'mae',
                'optimizer': 'adam',
                'epochs': 3,
                'batch_size': 300
            },
            {
                'trainSize': 0.7,
                'lookback': 8,
                'modelLayers': [
                    LSTM(10),
                ],
                'loss': 'mae',
                'optimizer': 'adam',
                'epochs': 4,
                'batch_size': 300
            },
            {
                'trainSize': 0.7,
                'lookback': 8,
                'modelLayers': [
                    LSTM(10),
                ],
                'loss': 'mae',
                'optimizer': 'adam',
                'epochs': 5,
                'batch_size': 300
            },
            {
                'trainSize': 0.7,
                'lookback': 8,
                'modelLayers': [
                    LSTM(10),
                ],
                'loss': 'mae',
                'optimizer': 'adam',
                'epochs': 6,
                'batch_size': 300
            },
            {
                'trainSize': 0.7,
                'lookback': 8,
                'modelLayers': [
                    LSTM(10),
                ],
                'loss': 'mae',
                'optimizer': 'adam',
                'epochs': 7,
                'batch_size': 300
            },
            {
                'trainSize': 0.7,
                'lookback': 8,
                'modelLayers': [
                    LSTM(10),
                ],
                'loss': 'mae',
                'optimizer': 'adam',
                'epochs': 8,
                'batch_size': 300
            },
            {
                'trainSize': 0.7,
                'lookback': 8,
                'modelLayers': [
                    LSTM(10),
                ],
                'loss': 'mae',
                'optimizer': 'adam',
                'epochs': 9,
                'batch_size': 300
            },
            {
                'trainSize': 0.7,
                'lookback': 8,
                'modelLayers': [
                    LSTM(10),
                ],
                'loss': 'mae',
                'optimizer': 'adam',
                'epochs': 10,
                'batch_size': 300
            },
            {
                'trainSize': 0.7,
                'lookback': 8,
                'modelLayers': [
                    LSTM(10),
                ],
                'loss': 'mae',
                'optimizer': 'adam',
                'epochs': 20,
                'batch_size': 300
            },
            {
                'trainSize': 0.7,
                'lookback': 8,
                'modelLayers': [
                    LSTM(10),
                ],
                'loss': 'mae',
                'optimizer': 'adam',
                'epochs': 30,
                'batch_size': 300
            },
            {
                'trainSize': 0.7,
                'lookback': 8,
                'modelLayers': [
                    LSTM(10),
                ],
                'loss': 'mae',
                'optimizer': 'adam',
                'epochs': 40,
                'batch_size': 300
            },
            {
                'trainSize': 0.7,
                'lookback': 8,
                'modelLayers': [
                    LSTM(10),
                ],
                'loss': 'mae',
                'optimizer': 'adam',
                'epochs': 50,
                'batch_size': 300
            },
            {
                'trainSize': 0.7,
                'lookback': 8,
                'modelLayers': [
                    LSTM(10),
                ],
                'loss': 'mae',
                'optimizer': 'adam',
                'epochs': 60,
                'batch_size': 300
            },
            {
                'trainSize': 0.7,
                'lookback': 8,
                'modelLayers': [
                    LSTM(10),
                ],
                'loss': 'mae',
                'optimizer': 'adam',
                'epochs': 70,
                'batch_size': 300
            },
            {
                'trainSize': 0.7,
                'lookback': 8,
                'modelLayers': [
                    LSTM(10),
                ],
                'loss': 'mae',
                'optimizer': 'adam',
                'epochs': 80,
                'batch_size': 300
            },
            {
                'trainSize': 0.7,
                'lookback': 8,
                'modelLayers': [
                    LSTM(10),
                ],
                'loss': 'mae',
                'optimizer': 'adam',
                'epochs': 90,
                'batch_size': 300
            },
            {
                'trainSize': 0.7,
                'lookback': 8,
                'modelLayers': [
                    LSTM(10),
                ],
                'loss': 'mae',
                'optimizer': 'adam',
                'epochs': 100,
                'batch_size': 300
            },
            {
                'trainSize': 0.7,
                'lookback': 8,
                'modelLayers': [
                    LSTM(10),
                ],
                'loss': 'mae',
                'optimizer': 'adam',
                'epochs': 200,
                'batch_size': 300
            },
            {
                'trainSize': 0.7,
                'lookback': 8,
                'modelLayers': [
                    LSTM(10),
                ],
                'loss': 'mae',
                'optimizer': 'adam',
                'epochs': 500,
                'batch_size': 300
            },
            {
                'trainSize': 0.7,
                'lookback': 8,
                'modelLayers': [
                    LSTM(10),
                ],
                'loss': 'mae',
                'optimizer': 'adam',
                'epochs': 1000,
                'batch_size': 300
            },
            {
                'trainSize': 0.7,
                'lookback': 8,
                'modelLayers': [
                    LSTM(10),
                ],
                'loss': 'mae',
                'optimizer': 'adam',
                'epochs': 2000,
                'batch_size': 300
            },
        ]
    }
]

ran = [
    {
                'trainSize': 0.7,
                'lookback': 8,
                'modelLayers': [
                    LSTM(10),
                ],
                'loss': 'mae',
                'optimizer': 'adam',
                'epochs': 1,
                'batch_size': 300
            },
            {
                'trainSize': 0.7,
                'lookback': 8,
                'modelLayers': [
                    LSTM(10),
                ],
                'loss': 'mae',
                'optimizer': 'adam',
                'epochs': 2,
                'batch_size': 300
            },]

